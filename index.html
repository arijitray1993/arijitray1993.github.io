<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-71242572-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-71242572-1');
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="I am a Computer Vision Ph.D. Student at Boston University. I am excited about how to make human-AI and AI-AI teams solve tasks effectively. Consequently, I am interested in and work on models that can interact with humans using natural language, models that can rationalize and explain their decisions, and models that leverage social media to do societal good.">
    <meta name="keywords" content="arijit, arijit ray, arren, arren ray, arijit arren ray, vqa, CLIP, large langauge models, LLM, generative AI, gen AI, diffusion models, image generation, generation, deep learning, AI, AIx, AI+x, ai, computer vision, natural language processing, conversational agents, explainable ai, xai, semafor, DARPA, SRI International, Virginia Tech, SRI, VT, vt, vqa relevance, gan, question answering, nlp, cv">
    <meta name="author" content="Arijit Ray">
    <title>Arijit Ray's Webpage</title>
	
	<!-- core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/animate.min.css" rel="stylesheet">
    <link href="css/prettyPhoto.css" rel="stylesheet">
    <link href="css/main.css" rel="stylesheet">
    <link href="css/responsive.css" rel="stylesheet">
	
	<link href="cover.css" rel="stylesheet">
	
    <!--[if lt IE 9]>
    <script src="js/html5shiv.js"></script>
    <script src="js/respond.min.js"></script>
    <![endif]-->       
 
</head><!--/head-->

<body class="homepage">

    <div class="carousel slide" style="min-height: 100%; background: url(images/network_bg.png); background-repeat: no-repeat; background-size: 100%; padding-top: 9%; padding-bottom: 12%;">        
        <div class="carousel-inner">
            <div class="container">
                <div class="row">
                    <div class="col-md-6">
                        <div class="row" style="padding-bottom: 20px;">
                            <div class="col">
                                <p><img src="images/profpic3.jpg" class="img-circle" width="35%" height="12%" style="padding:10px"></p>
                                <!--<h1 class="animate" style="font-size:2.3em"><font color="#382b42">Hello World!<span class="spananimate">|</span> </font> </h1>-->
                                <h2 class="animate" style="font-size:1.6em"><font color="#382b42"> <b> Arijit Ray.</b><span class="spananimate">|</span> </font></h2>
                                <h3 class="animate" style="font-size:1.2em"><a href="http://ai.bu.edu/" style="color:#382b42;"> <b> Computer Science Ph.D. Student </a> <span class="spananimate"><font color="#382b42">|</font></span> </b> </h3>
                                <!--<h3 class="animate" style="font-size:1.2em"><a href="http://ai.bu.edu/" style="color:#382b42;"> Research Scientist Intern, Meta AI (FAIR)</a></b> <span class="spananimate"> <font color="#382b42">|</font></span> </h3> -->
                                
                                
                            </div>
                        </div>
                        <div class="row" style="padding-bottom: 2px; padding-left: 9px;">
                            <div class="col">
                                <a href="#publications" class="btn btn-primary" role="button">Projects</a>
                                <a target="_" href="RayCV.pdf" class="btn btn-primary" role="button">CV</a>   
                                <a href="#tutorials" class="btn btn-primary" role="button">Tutorials</a>   
                                <a target="_" href="https://github.com/arijitray1993" class="btn btn-primary" role="button">Github</a>  
                            </div>
                        </div>
                        <!--<div class="row" style="padding-bottom: 20px; padding-left: 9px;">
                            <div class="col">
                                <a target="_" href="aix/index.html" class="btn btn-primary" role="button">AI+x Conversations</a>
                            </div>
                        </div>-->
                        <div class="row" style="padding-bottom: 20px; padding-left: 10px;">
                            <div class="col" style="font-size: larger;">
                                <br>
                                <a target="_" href="https://scholar.google.com/citations?user=7UgubNoAAAAJ&hl=en" role="button"><img src="https://img.icons8.com/ios/50/000000/google-scholar--v2.png" width="25"> <b>Google Scholar</b></a>   
                            </div>
                        </div>
                        <div class="row" style="padding-bottom: 20px; padding-left: 10px;">
                            <div class="col">
                                <a target="_" href="https://twitter.com/ARRay693"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" class="bi bi-twitter" viewBox="0 0 16 16">
                                    <path d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z"/>
                                </svg></a>
                                &nbsp;
                                <a target="_" href="https://www.linkedin.com/in/ray93/"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
                                    <path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"/>
                                </svg></a>  
                            </div>
                        </div>
                        
                    </div>
                    <div class="col-md-6" id="about_me" >
                        <div class="row" style="padding-left: 5px;padding-right: 5px;">
                            <p class="lead" align=justify>I wish to teach machines to help humans achieve more in the world.</h2>
                            
                                <h2>About me and my research:</h2>
                            <p class="lead-small" align=justify>
                                I am a <a href="http://ai.bu.edu/">Computer Vision <b>Ph.D. Student</b></a> at <b><a href="https://www.bu.edu">Boston University (BU)</a></b>, advised by
                                <b><a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a></b> and 
                                <b><a href="http://bryanplummer.com/">Bryan Plummer</a></b>. I collaborate closely with <b><a href="http://www.ranjaykrishna.com/index.html">Ranjay Krishna</a></b> from the <b>University of Washington</b>
                                and am a student collaborator in the <b>PRIOR Team</b> at <b><a href="https://allenai.org/">Allen AI</a></b>.
                                I received my M.S from Virginia Tech, advised by <b><a href="https://faculty.cc.gatech.edu/~parikh/">Devi Parikh</a></b>.  
                            </p>
                            
                            <p class="lead-small" align=justify> 
                                Recently, I am interested in endowing AI models with spatial intelligence to help them effectively take actions in the 3D world. 
                                Since obtaining such annotations is expensive, I wish to teach models to imagine scenarios in 3D simulations and learn from them to generalize to the real world.
                                I also enjoy creating ecosystems that encourage creative building. Hence, I am a member of the  <a href="https://aiforimpact.github.io/">AI for Impact Venture Studio</a> at <a href="https://www.mit.edu/">MIT</a>.
                            </p>

                            <p class="lead-small", align=justify>If you are interested to collaborate or just chat about research on multimodal models to help human creativity, say hi! </p>
                        </div>
                        <div class="row" style="padding-left: 5px;padding-right: 5px;">
                            <div class="col-md-4" align="center">
                                <a href="https://allenai.org/">
                                <img src="images/ai2logo.png" class="img-rounded" alt="ai2" style="height:40px">
                                
                                <div class="caption">
                                    <p align="center" class="lead-small">Student Collaborator, Allen AI (PRIOR), 2024</p>
                                </div>
                                </a>
                            </div>
                            <div class="col-md-4" align="center">
                                <a href="https://x.company/">
                                <img src="images/X_logo.png" class="img-rounded" alt="googleX" style="height:40px">
                                
                                <div class="caption">
                                    <p align="center" class="lead-small">AI Resident, Mineral, Google X, 2023</p>
                                </div>
                                </a>
                            </div>
                            <div class="col-md-4" align="center">
                                
                                <a href="https://ai.meta.com/research/">
                                <img src="images/meta_ai.jpeg" class="img-rounded" alt="meta_ai_fair" style="height:30px">
                                
                                <div class="caption">
                                    <p align="center" class="lead-small">Research Intern, Facebook AI Research, 2022</p>
                                </div>
                                </a>
                               
                            </div>
                            
                        </div>
                        <div class="row" style="padding-left: 5px;padding-right: 5px;">
                            <div class="col-md-6" align="center">
                               
                                <a href="https://www.sri.com/">
                                <img src="images/sri_logo.jpeg" class="img-rounded" alt="sri" style="height:40px">
                               
                                <div class="caption">
                                    <p align="center" class="lead-small">Computer Scientist, 2017-2021</p>
                                </div>
                                </a>
                               
                            </div>
                            <div class="col-md-6" align="center">
                                
                                <a href="https://bluerivertechnology.com/">
                                <img src="images/blue_river.jpeg" class="img-rounded" alt="blueriver" style="height:40px">
                                <div class="caption">
                                    <p align="center" class="lead-small">Deep Learning Intern, 2016, acquired by John Deere</p>
                                </div>
                                </a>
                                
                            </div>
                        </div>
                        
                        
                        <!--<p class="lead" align=justify>    
                            I have been fortunate to work in close collaboration with amazing researchers such as
                            <a href="http://www.cc.gatech.edu/~dbatra/index.html">Prof. Dhruv Batra</a>, 
                            <a href="http://web.engr.oregonstate.edu/~leestef/">Prof. Stefan Lee</a>,
                            <a href="https://sites.google.com/view/ajaydivakaran/">Dr. Ajay Divakaran</a>, 
                            <a href="https://scholar.google.com/citations?user=iD6QaXcAAAAJ&hl=en">Dr. Yi Yao</a>, and
                            <a href="https://scholar.google.com/citations?user=KrkPjxMAAAAJ&hl=en">Dr. Giedrius Burachas</a>. 

                        </p> --> 
            
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="row">
            <div class="col-md-12">
                <h2 style="font-size:1.7em">Highlights:</h2>
                <h3>
                    <ul>
                        <li class="lead-small">2024: Our <b><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Feedback-Guided_Autonomous_Driving_CVPR_2024_paper.pdf">paper</a></b> on feedback-guided autonomous driving got accepted to CVPR 2024 as a highlight. </li>
                        <li class="lead-small">2023: Our <b><a href="https://arxiv.org/abs/2305.03689">paper</a></b> on evaluating and adapting models for compositional reasoning got accepted to NeurIPS. </li>
                        <li class="lead-small">2023: One of my student's <b><a href="https://arxiv.org/abs/2308.16741">paper</a></b> got accepted as an oral at an <a href="https://iccv23-wecia.github.io/">ICCV Workshop</a> 2023. </li> 
                        <li class="lead-small">2023: I am excited to be spending my summer as an AI Resident at <b>Google X</b> (Mineral), working on adapting multimodal language models for object localization. </li>
                        <li class="lead-small">2022: We started <b><a href="aix/index.html">[AI+X] of BU and Harvard</a></b>, a group where we brainstorm research/venture ideas on how AI can impact concurrent research areas.</li>
                        <li class="lead-small">2022: I am excited to be spending my summer as a Research Scientist Intern at <b>Meta (Facebook) AI</b> (FAIR), working on the compositionality of large vision-language models.</li>
                        <li class="lead-small">2019: I <b>won runners-up</b> at the SRI CVT Shark Tank Competition that supported my <b><a href="papers/persuade/persuade.html">mini-project on understanding image-text content</a></b> to reduce radicalization of opinions on social media.</li> 
                        <li class="lead-small">2017: The weed vs plant detection system I helped develop for precision fertilizing played a key part in the acquisition of Blue River Technologies by John Deere for <b>305 million USD</b>. </li>
                        <li class="lead-small">2016: My first <b><a href="https://arxiv.org/abs/1606.06622">paper</a></b> got accepted to EMNLP.</li>
                        <li class="lead-small">2014: Our UAV for <b>helping locating natural disaster victims</b> was featured in National News : Deccan Chronicle, Indian Express</li>
                        <li class="lead-small">2013: I <b>won</b> a <b>silver medal</b> at SRM University Research Day for my white-paper presentation on an Electro-Mechanical Exoskeleton.</li>
                        <li class="lead-small">2012: I won an <b>Academic Merit Scholarship</b> from SRM University that waives a part of my undergraduate tuition.</li>  
                    </ul>	
                </h3>
            </div>
        </div>
        

        <div class="row" id="publications">
            <div class="col-md-12">
                <h2 style="font-size:1.7em"><b>Projects/Publications:</b></h2>
                <div class="accordion">
                    <div class="panel-group" id="accordion1">
                        <div class="panel panel-default">
                            <div class="panel-heading active">
                                <h3 class="panel-title">
                                    <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordion1" href="#collapsezero1">
                                    Publications: <i class="fa fa-angle-right pull-right"></i>
                                    </a>
                                </h3>
                            </div>
    
                            <div id="collapsezero1" class="panel-collapse collapse in">
                                <div class="panel-body">
                                    <div class="media accordion-inner">
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <h2> 2024 </h2>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="papers/images/sat_teaser.png" height="170">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small"> 
                                                    Arijit Ray, 
                                                    <a href="https://duanjiafei.com/">Jiafei Duan</a>,  
                                                    <a href="https://cs-people.bu.edu/rxtan/">Reuben Tan</a>,  
                                                    <a href="https://scholar.google.com/citations?user=qvUTYsUAAAAJ&hl=en">Dina Bashkirova</a>,  
                                                    <a href="https://rosehendrix.com/">Rose Hendrix</a>,  
                                                    <a href="https://ehsanik.github.io/">Kiana Ehsani</a>,  
                                                    <a href="https://anikem.github.io/">Aniruddha Kembhavi</a>,  
                                                    <a href="https://bryanplummer.com/">Bryan A. Plummer</a>,  
                                                    <a href="https://ranjaykrishna.com/index.html">Ranjay Krishna</a>*,  
                                                    <a href="https://kuohaozeng.github.io/">Kuo-Hao Zeng</a>*, 
                                                    <a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>*, 
                                                    <b>SAT: Spatial Aptitude Training for Multimodal Language Models</b>, 
                                                    <a href="#">(preprint)</a>,
                                                    <a href="https://arijitray1993.github.io/SAT/">[webpage]</a>
                                                    <a href="https://cs-people.bu.edu/array/research/SAT/SAT_arxiv.pdf">[paper]</a> 
                                                    <a href="#">[arxiv coming soon]</a>, <a href="#">[code/data coming soon]</a> 
                                                </p>
                                                <p class="lead-small">
                                                    Tl; dr: Simulated spatial aptitude data (SAT) can improve spatial reasoning in real images for MLMs 
                                                    while maintaining pretraining commonsense. When instruction-tuned on SAT, LLaVA-13B matches some larger MLMs like GPT4-V and Gemini-3-1.0 in spatial reasoning.
                                                </p>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="papers/images/fed_teaser.png" height="120" width="210">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small"> 
                                                    <a href="https://jimuyangz.github.io/">Jimuyang Zhang</a>,
                                                    <a href="https://tzmhuang.github.io/">Zanming Huang</a>, 
                                                    Arijit Ray, 
                                                    <a href="https://eshed1.github.io/">Eshed-Ohn Bar</a>, 
                                                    <b>FED: Feedback-Guided Autonomous Driving</b>, 
                                                    <b><a href="https://cvpr.thecvf.com/">CVPR 2024 (Highlight)</a></b>, 
                                                    <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Feedback-Guided_Autonomous_Driving_CVPR_2024_paper.pdf">[paper]</a> 
                                                </p>
                                                <p class="lead-small">
                                                    Tl; dr: MLMs can benefit autonomous driving by understanding natural language feedback and refining the next waypoint prediction. 
                                                </p>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div class="col-md-12">
                                                <h2> 2023 </h2>
                                            </div>
                                        </div>

                                        
                                            
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/lasagna.png" height="155">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small"> 
                                                    <a href="https://cs-people.bu.edu/dbash/">Dina Bashkirova</a>, 
                                                    Arijit Ray, 
                                                    <a href="https://contact.georgetown.edu/view/rm2083/">Rupayan Mallick</a>, 
                                                    <a href="https://bargal.georgetown.domains/">Sarah Adel Bargal</a>, 
                                                    <a href="https://jimmie33.github.io/">Jianming Zhang</a>, 
                                                    <a href="https://ranjaykrishna.com/index.html">Ranjay Krishna</a>, 
                                                    <a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>, 
                                                    <b>Lasagna: Layered Score Distillation for Disentangled Object Relighting</b>, 
                                                    <a href="https://arxiv.org/pdf/2312.00833.pdf">[arxiv]</a> <a href="https://github.com/dbash/lasagna?tab=readme-ov-file">[project page, data]</a> </p>
                                                <p class="lead-small">
                                                    Tl; dr: Synthetcially generated examples are effective in teaching physics-aware edits like relighting if we use score-distillation to avoid overfitting.  
                                                </p>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/teaserfig_compositionality.png" height="205">
                                            </div>
                                            <div class="col-md-9">
                                                
                                                <p class="lead-small" style="align-items: center;"> 
                                                    Arijit Ray, 
                                                    <a href="https://filipradenovic.github.io/">Filip Radenovic</a>,
                                                    <a href="https://scholar.google.co.in/citations?user=KJNUEgkAAAAJ&hl=en">Abhimanyu Dubey</a>, 
                                                    <a href="https://bryanplummer.com/">Bryan Plummer</a>, 
                                                    <a href="https://ranjaykrishna.com/index.html">Ranjay Krishna</a>, 
                                                    <a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>,  
                                                    <b>Cola: A Benchmark for Compositional Text-to-image Retrieval</b>, <b><a href="https://nips.cc/">NeurIPS 2023</a></b>,
                                                    <a href="https://arxiv.org/abs/2305.03689">[arxiv]</a> <a href="https://cs-people.bu.edu/array/research/cola/">[project page, data]</a> 
                                                </p>
                                                <p class="lead-small">
                                                    Tl; dr: Tuning multimodal layers improve the unseen compositional reasoning ability in CLIP-style vision-language models the most over tuning other parts of the model.  
                                                </p>
                                            </div>
                                        </div>
                               
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/teaser_emotion.png" height="70">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small"> 
                                                    <a href="https://kdeng55.github.io/website/">Katherine Deng</a>, 
                                                    Arijit Ray, 
                                                    <a href="https://cs-people.bu.edu/rxtan/">Reuben Tan</a>, 
                                                    <a href="https://saadia-gabriel.github.io/">Saadia Gabriel</a>, 
                                                    <a href="https://bryanplummer.com/">Bryan A. Plummer</a>, 
                                                    <a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>,  
                                                <b>Socratis: Are Large Multimodal Models Emotionally Aware?</b>, <b><a href="https://nips.cc/">ICCV Workshops 2023 (oral)</a></b>, <a href="https://iccv23-wecia.github.io/">Workshop on Emotionally and Culturally Intelligent AI</a>,
                                                <a href="https://arxiv.org/abs/2308.16741">[arxiv]</a> <a href="https://kdeng55.github.io/socratis-website/">[project page, data]</a> </p>
                                                <p class="lead-small">
                                                    Tl; dr: A preliminary study showing MLMs seem to lack diverse perspectives for why different people may feel differently while viewing the same image-text content.  
                                                </p>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <h2> 2022 </h2>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/teaser_audio_sep.png" height="150">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">

                                                <p class="lead-small"> 
                                                    <a href="https://cs-people.bu.edu/rxtan/">Reuben Tan</a>,
                                                    Arijit Ray, 
                                                    <a href="https://cs-people.bu.edu/aburns4/">Andrea Burns</a>, 
                                                    <a href="https://bryanplummer.com/">Bryan A. Plummer</a>, 
                                                    <a href="https://www.justinsalamon.com/">Justin Salamon</a>, 
                                                    <a href="https://www.urinieto.com/about/">Oriol Nieto</a>, 
                                                    <a href="https://bryanrussell.org/">Bryan Russell</a>, 
                                                    <a href="http://ai.bu.edu/ksaenko.html">Kate Saenko</a>,   
                                                <b>Language-Guided Audio-Visual Source Separation via Trimodal Consistency</b>, <b><a href="https://cvpr2023.thecvf.com/">CVPR 2023</a></b>, <a href="https://arxiv.org/abs/2303.16342">[arxiv]</a> <a href="https://cs-people.bu.edu/rxtan/projects/VAST/">[code]</a> 
                                            </p>
                                            <p class="lead-small">
                                                Tl; dr: We can use language as a bridge to teach models to perform audio-visual sound separation.  
                                            </p>
                                            </div>
                                        </div>
                                        
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>

                                        <div class="row">
                                            <div class="col-md-12">
                                                <h2> 2021 </h2>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/persuade_teaser.png" height="50">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small">
                                                    <a href="https://www.sri.com/people/ajay-divakaran/">Ajay Divakaran</a>, 
                                                    <a href="https://www.ksikka.com/">Karan Sikka</a>, 
                                                    Arijit Ray, 
                                                    <a href="https://scholar.google.com/citations?user=zSIbUH4AAAAJ&hl=en">Xiao Lin</a>, 
                                                    <a href="https://www.linkedin.com/in/yi-yao-b75137a/">Yi Yao</a>, <b>User-targeted content generation using multimodal embeddings</b>, <b><a href="https://patentimages.storage.googleapis.com/33/12/c9/a8ba61d5bff8fc/US20210297498A1.pdf">US Patent App. 17/191,698</a></b> <a href="papers/persuade/persuade.html">[webpage]</a> </p>
                                            </div>
                                        </div>
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/xai_counterfactual.jpeg" height="40">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small">
                                                    <a href="https://www.linkedin.com/in/kamran-alipour/">Kamran Alipour</a>, 
                                                    Arijit Ray, 
                                                    <a href="https://scholar.google.com/citations?user=zSIbUH4AAAAJ&hl=en">Xiao Lin</a>, 
                                                    <a href="https://mcogswell.io/">Michael Cogswell</a>, 
                                                    <a href="https://web.eng.ucsd.edu/~jschulze/">Jurgen Schulze</a>, 
                                                    <a href="https://www.linkedin.com/in/yi-yao-b75137a/">Yi Yao</a>, 
                                                    <a href="https://scholar.google.com/citations?user=KrkPjxMAAAAJ&hl=en">Giedrius Burachas</a>, <b>Improving Users' Mental Model with Attention-directed Counterfactual Edits</b>, <b><a href="https://onlinelibrary.wiley.com/journal/26895595">2021 Applied AI Letters (Wiley)</a></b> <a href="https://www.authorea.com/users/422041/articles/527829-improving-users-mental-model-with-attention-directed-counterfactual-edits?commit=3378fd22cbdd71d561857417c70fcb2e773e6757">[pdf]</a> </p>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/error_map_teaser.png" height="130">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small">
                                                    Arijit Ray, 
                                                    <a href="https://mcogswell.io/">Michael Cogswell</a>, 
                                                    <a href="https://scholar.google.com/citations?user=zSIbUH4AAAAJ&hl=en">Xiao Lin</a>, 
                                                    <a href="https://www.linkedin.com/in/kamran-alipour/">Kamran Alipour</a>, 
                                                    <a href="https://www.sri.com/people/ajay-divakaran/">Ajay Divakaran</a>, 
                                                    <a href="https://www.linkedin.com/in/yi-yao-b75137a/">Yi Yao</a>, 
                                                    <a href="https://scholar.google.com/citations?user=KrkPjxMAAAAJ&hl=en">Giedrius Burachas</a>, 
                                                    <b>Knowing What VQA Does Not: Pointing to Error-Inducing Regions to Improve Explanation Helpfulness</b>, <b><a href="https://onlinelibrary.wiley.com/journal/26895595">2021 Applied AI Letters (Wiley)</a></b>, <a href="https://www.authorea.com/users/422054/articles/527831-generating-and-evaluating-explanations-of-attended-and-error-inducing-input-regions-for-vqa-models">[pdf]</a> <a href="https://arxiv.org/abs/2103.14712">[arXiv]</a> <a href="https://arijitray1993.github.io/helpfulness_evaluation/">[Project Page]</a> </p>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <h2> 2019 </h2>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/consistency_vqa.png" height="80">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small">
                                                    Arijit Ray, 
                                                    <a href="https://www.ksikka.com/">Karan Sikka</a>, 
                                                    <a href="https://www.sri.com/people/ajay-divakaran/">Ajay Divakaran</a>, 
                                                    <a href="https://web.engr.oregonstate.edu/~leestef/">Stefan Lee</a>, 
                                                    <a href="https://scholar.google.com/citations?user=KrkPjxMAAAAJ&hl=en">Giedrius Burachas</a>, 
                                                    <b>Sunny and Dark Outside?! Improving Answer Consistency in VQA through Entailed Question Generation </b>, <b><a href="https://www.emnlp-ijcnlp2019.org/">(EMNLP 2019)</a></b>, also at CVPR-W 2019 VQA and Visual Dialog Workshop, <a href="https://arxiv.org/abs/1909.04696">[arXiv]</a>, <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:ShV01ZdBlNMJ:scholar.google.com/&output=citation&scisdr=CgXjcSlzEK_QoWyqPIU:AAGBfm0AAAAAXYevJIXx9ICCQTt8kgsw5WeyrTAzWxUC&scisig=AAGBfm0AAAAAXYevJOaNssRITzak7FcGP1o_N8LZQomU&scisf=4&ct=citation&cd=-1&hl=en&scfhb=1">[bibTex]</a> <a href="https://arijitray1993.github.io/ConVQA/">[Data]</a></p>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
    
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/vqa_20questions.png" height="140">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small">Arijit Ray, 
                                                    <a href="https://www.linkedin.com/in/yi-yao-b75137a/">Yi Yao</a>, 
                                                    <a href="https://www.sri.com/people/rakesh-kumar/">Rakesh Kumar</a>, 
                                                    <a href="https://www.sri.com/people/ajay-divakaran/">Ajay Divakaran</a>, 
                                                    <a href="https://scholar.google.com/citations?user=KrkPjxMAAAAJ&hl=en">Giedrius Burachas</a>, 
                                                    <b>Can You Explain That: Lucid Explanations Help Human-AI Collaboratve Image Retrieval </b>, <b><a href="https://www.humancomputation.com">(AAAI-HCOMP 2019)</a></b>, <a href="https://arxiv.org/abs/1904.03285">[arXiv]</a>, <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:OEonmeXn6X8J:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAXK-oTg3PAUilxsc5bmpDaedN5P4wXuzF&scisf=4&ct=citation&cd=-1&hl=en">[bibTex]</a> <a href="https://techxplore.com/news/2019-04-exag-image-guessing-game-machine-explanations.html">[press coverage]</a> </p>
                                                </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
        
                                        <div class="row">
                                            <div class="col-md-12">
                                                <h2> 2016 </h2>
                                            </div>
                                        </div>
                                        
                                        <div class="row">
                                            <div style="text-align: center; vertical-align: middle; border: none;" class="col-md-3">
                                                <img src="images/papers/vqa_relevance.png" height="100">
                                            </div>
                                            <div style="vertical-align: middle;" class="col-md-9">
                                                <p class="lead-small">Arijit Ray, 
                                                    <a href="https://computing.ece.vt.edu/~gordonac/">Gordon Christie</a>, 
                                                    <a href="https://www.cs.unc.edu/~mbansal/">Mohit Bansal</a>, 
                                                    <a href="https://faculty.cc.gatech.edu/~dbatra/">Dhruv Batra</a>, 
                                                    <a href="https://faculty.cc.gatech.edu/~parikh/">Devi Parikh</a>,<b> "Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions."</b>, <b><a href="http://www.emnlp2016.net/">(EMNLP 2016)</a></b>. <a href="https://arxiv.org/abs/1606.06622">[pdf]</a> <a href="https://github.com/arijitray1993/VQARelevance">[code]</a> <a href="https://www.youtube.com/watch?v=wZJmHs6qSyY">[Video]</a></p>
                                                </div>
                                        </div>

                                        <div class="row">
                                            <div class="col-md-12">
                                                <hr>
                                            </div>
                                        </div>
                                    
                
                                    </div>
                                </div>
                            </div>
                        </div>
    
                        <div class="panel panel-default">
                            <div class="panel-heading">
                                <h3 class="panel-title">
                                    <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordion1" href="#collapseOne1">
                                        Course/Mini Projects:
                                        <i class="fa fa-angle-right pull-right"></i>
                                    </a>
                                </h3>
                            </div>
                            <div id="collapseOne1" class="panel-collapse collapse">
                                <div class="panel-body">
                                    <div class="media accordion-inner">      
                                        
                                        <div class="media-body">
                                            <p class="lead-small">Prashant Chandrasekar, Xuan Zhang, Saurabh Chakravarty, Arijit Ray, John Krulick, and Alla Rozovskaya,<b> "The Virginia Tech System at CoNLL-2016 Shared Task on Shallow Discourse Parsing"</b>, <b><a href="http://www.cs.brandeis.edu/~clp/conll16st/">CoNLL Shared Task (2016)</a></b>.</p>
                                            <hr>
                                        </div>

                                        <div class="media-body">
                                            <p class="lead-small">The Art of Deep Connection - Towards Natural and Pragmatic Conversational Agent Interactions. <a href="https://vtechworks.lib.vt.edu/handle/10919/78335">[Master's Thesis]</a>, Virginia Tech E-Library, 2017 </p>
                                            <hr>
                                        </div>               
                                        
                                        <div class="media-body">
                                            <p class="lead-small"> Make RBF Networks Fast Again- Exploiting Multi-Threaded Computing to Speed Up RBF Networks, Multiprocessor Programming Class Project, Fall 2016, <a href="https://filebox.ece.vt.edu/~ray93/papers/rbfConcurrent.pdf">[draft paper]</a> <a href="https://github.com/arijitray1993/TensorFlowRBF">[code]</a></p>
                                            <hr>
                                        </div>
    
                                        <div class="media-body">
                                            <p class="lead-small"><a href="https://filebox.ece.vt.edu/~aroma/web/cv_project_15/home.html">Object Prediction using Image Context</a>: Predict next object in an image reasoned on present image context in a sequential manner, Computer Vision Class Project Fall 2015</p>
                                            <hr>
                                        </div>
        
                                        <div class="media-body">
                                            <p class="lead-small"><a href="http://godel.ece.vt.edu/commonSense/">Online Demo for Predicting Plausibility of Common Sense Assertions</a>: Enter a three-phrase tuple to assess the plausibility score based on a joint language-vision common-sense reasoning, Class Project, Fall 2015</p>
                                            <hr>
                                        </div>
        
                                        <div class="media-body">
                                            <p class="lead-small"><a href="#">Learning to Listen: Matching Cover songs with Original Productions</a>: Match Original Songs to Cover Songs using an Ensemble of Supervised and Unsupervised Approaches, Machine Learning Class Project, Fall 2015. </p>
                                            <hr>
                                        </div>
    
    
                                        <div class="media-body">
                                            <p class="lead-small">Ray, Arijit, Kishan Prudhvi Guddanti, and N. Chellammal. "An Approach to Intelligent Traction Control Using Regression Networks and Anomaly Detection.", Junior (3rd Year) Semester Project, Fall 2013, published in <b>Springer Applied Artificial Intelligence </b> 29.6 (2015): 597-616.</p>
                                        </div>    
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div style="padding-bottom: 40px;"></div>
        
        
          
        
        <div class="row" id="tutorials">
            
                <div class="col-md-12">
                    <h2 style="font-size:1.7em"><b>Tutorials</b></h2>
                    <ul class="list-group">
                        <li class="list-group-item">
                            <div class="media">
                                <div class="pull-left">
                                    <a target="_" href="https://arijitray1993.github.io/CARLA_tutorial/">
                                        <img src="images/carla_icon.png" class="media-object" style="width:200px">
                                    </a>
                                </div>
                                <div class="media-body">
                                    <h4 class="media-heading">
                                        <a target="_" href="https://arijitray1993.github.io/CARLA_tutorial/">CARLA Tutorial</a>
                                        <a target="_" href="https://github.com/arijitray1993/CARLA_tutorial">[Github Code]</a>
                                    </h4>
                                    <p>Tutorial code on how to run CARLA without a display on an Ubuntu server and get image frames/sensor data</p>
                                </div>
                            </div>
                        </li>
                    </ul>
                </div>
           
        </div>

        <div class="row">
            <div class="features">             
                <div class="col-md-12">
                    <div class="feature-wrap">
                        <h2 style="font-size:1.7em"><b>Press Coverage</b></h2>
                        <ul>
                            <li>
                                <b>2023: Generative AI Podcast:</b> <a href="https://podcasts.apple.com/us/podcast/generative-ai-using-ai-to-predict-social-media-and/id1660801320?i=1000605725626"> I was interviewed on AI and analyzing social media responses using language models.</a>
                            </li>
                            <li>
                                <b>2019: TechXplore, Phys.org:</b> <a href="https://techxplore.com/news/2019-04-exag-image-guessing-game-machine-explanations.html">An image-guessing game to evaluate the helpfulness of machine explanations </a>
                            </li>
                            <li>
                                <b>2014: Deccan Chronicle, Indian Express, Engineering.Careers360:</b> UAV with Facial Recognition Capabilities for helping locating natural disaster victims, <a href="http://www.newindianexpress.com/cities/chennai/2014/sep/20/UAV-With-Facial-Recognition-Takes-Flight-662823.html">Click here</a>
                            </li>
                        </ul>
                    </div>
                </div><!--/.col-md-4-->
            </div>
        </div>

        <div class="row">
            <div class="col-md-12">
                <div class="feature-wrap">
                    <!--<i><img width="70%" class="img-circle" src="images/hike.jpg"></img></i>-->
                    <h2 style="font-size:1.7em">Collaborators</h2>
                    <p class="lead">
                        Some of the amazing people I have been fortunate to work with:
                    </p>
                    <p>
                        <a href="http://www.cc.gatech.edu/~dbatra/index.html">Prof. Dhruv Batra (at Virgina Tech)</a>, 
                            <a href="http://web.engr.oregonstate.edu/~leestef/">Prof. Stefan Lee (at Virgina Tech and SRI Intl.)</a>,
                            <a href="https://scholar.google.com/citations?user=Gd9HQn2UsNoC&hl=en">Dr. Dhruv Mahajan (at FAIR)</a>,
                        <a href="https://filipradenovic.github.io/">Dr. Filip Radenovic (at FAIR)</a>,
                        <a href="https://abhimanyudubey.github.io/">Dr. Abhimanyu Dubey (at FAIR)</a>,
                            <a href="https://sites.google.com/view/ajaydivakaran/">Dr. Ajay Divakaran (at SRI Intl)</a>, 
                            <a href="https://scholar.google.com/citations?user=iD6QaXcAAAAJ&hl=en">Dr. Yi Yao (at SRI Intl)</a>,
                            <a href="https://scholar.google.com/citations?user=KrkPjxMAAAAJ&hl=en">Dr. Giedrius Burachas (at SRI Intl)</a>,
                            <a href="https://www.kezhenchen.net/">Dr. Kezhen Chen (at Google X, Mineral)</a>
                    </p>
                </div>
            </div> 
        </div>

        <div class="row">
            <div class="col-md-12">
                <div class="feature-wrap">
                    <!--<i><img width="70%" class="img-circle" src="images/hike.jpg"></img></i>-->
                    <h2 style="font-size:1.7em">Hobbies</h2>
                    <h3>When I am not training LLMs, I love going to techno (a subgenre of electronic music) fests, <a href="https://photos.app.goo.gl/Dk7KDKqC5DGYYfey9" style="text-decoration: underline" target="_blank">making latte art</a>, and <a href="https://github.com/arijitray1993/raspberrypi_surveillance" style="text-decoration: underline" target="_blank">engineering simple gadgets</a>. 
                        In middle school, I opened an informal research society to encourage fellow students to 
                        take an interest in science by constructing simple gadgets. We won multiple accolades in school and city-level exhibitions. </h3>
                </div>
            </div> 
        </div>

        

        <div class="row">
            <div class="col-md-12">
                <div class="feature-wrap">
                    <!--<i><img width="70%" class="img-circle" src="images/hike.jpg"></img></i>-->
                    <h2 style="font-size:1.7em">Miscellanea</h2>
                    <ul>
                        <li>
                            Paper writing tips and tricks: <a href="https://faculty.cc.gatech.edu/~parikh/citizenofcvpr/static/slides/malik_write_good_paper.pdf" style="text-decoration: underline">Writing a good paper (by Jitendra Mailk)</a>, 
                            <a href="https://deviparikh.substack.com/p/shortening-papers-to-fit-page-limits-97601318681d" style="text-decoration: underline">shortening papers (by Devi Parikh)</a>, 
                            <a href="https://docs.google.com/presentation/d/1PZj0Sev2yjDu9NNr96S_wwjKCgIDhGmLjW1vtQpDhlk/edit#slide=id.p" style="text-decoration: underline">Writing Introductions (by Kate Saenko)</a>
                        </li>
                        <li>
                            <a href="http://www.paulgraham.com/articles.html" style="text-decoration: underline">Paul Graham's essays:</a> Some of my favorites: <a href="http://www.paulgraham.com/newideas.html" style="text-decoration: underline">Crazy New Ideas</a>,
                             <a href="http://www.paulgraham.com/genius.html" style="text-decoration: underline">The Bus Ticket Theory of Genius</a>, <a href="http://www.paulgraham.com/think.html" style="text-decoration: underline">How to Think for Yourself</a>, 
                             <a href="https://paulgraham.com/cities.html" style="text-decoration: underline">Cities and Ambition</a>
                            
                        </li>
                        <li>
                            On social media: Is it bad or beneficial to society, and why running a social media is hard: <a href="https://twitter.com/yishan/status/1514938507407421440" style="text-decoration: underline">Twitter thread</a> by Yishan (former CEO of Reddit).
                        </li>
                        <li>
                            <a href="miscc/quotes.html" style="text-decoration: underline">Quotes</a>
                        </li>
                    </ul>
                </div>
            </div> 
        </div>


    </div>

    <div style="padding-bottom: 30px;"></div>
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="media contact-info">
                    <div class="media-body">
                        <h2><b><u>Contact Me</u></b></h2>
                    </div>
                    <div class="pull-left">
                        <i class="fa fa-phone"></i>
                    </div>
                    <div class="media-body">
                        <h2>Have a question?</h2>
                        <p>Best way to reach me would be to drop an email to array at bu dot edu. </p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    
    <footer id="footer" class="midnight-blue">
        <div class="container">
            <div class="row">		               
                    &copy; 2024 Arijit Ray. Template modified by permission from shapebootstrap.com            
            </div>
        </div>
    </footer>

   

    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/jquery.prettyPhoto.js"></script>
    <script src="js/jquery.isotope.min.js"></script>
    <script src="js/main.js"></script>
    <script src="js/wow.min.js"></script>
    
</body>
</html>


<!--<div class="panel panel-default">
                            <div class="panel-heading">
                              <h3 class="panel-title">
                                <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordion1" href="#collapseTwo1">
                                  Selected Presentations:
                                  <i class="fa fa-angle-right pull-right"></i>
                                </a>
                              </h3>
                            </div>
                           <div id="collapseTwo1" class="panel-collapse collapse">
                            <div class="panel-body">
                                <div class="media accordion-inner">
                                        <div class="media accordion-inner">
                                            <div class="media-body">
						                        <p> <a target="_blank" href="https://docs.google.com/presentation/d/1Au4k_-uoP3m6Ng6xFlMwziHhWuf4Yv9TNCu6Ndr7Dpk/pub?start=false&loop=false&delayms=60000"> People, Faces, and more...</a></p>
					                         </div>
                                            <div class="media-body">
						                        <p> <a target="_blank" href="https://docs.google.com/presentation/d/1WuXm45OeK5WdRN9pej9c-0-xSj5JEAXt1uGHAgBx9Rc/pub?start=false&loop=false&delayms=30000"> MACV Talk on the Visual Twenty Questions Game </a></p>
					                         </div>

                                        </div>
                               </div>
                            </div>
                          </div>
                        </div>
-->
